Q5. Use Naive bayes, K-nearest, and Decision tree classification algorithms and build classifiers.
Divide the data set into training and test set. Compare the accuracy of the different classifiers
under the following situations:
5.1 a) Training set = 75% Test set = 25% b) Training set = 66.6% (2/3rd of total), Test set =
33.3%
5.2 Training set is chosen by i) hold out method ii) Random subsampling iii) Cross-Validation.
Compare the accuracy of the classifiers obtained.
5.3 Data is scaled to standard format.





from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_splitfrom sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.tree import plot_tree
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_reportimport matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import warnings
iris = load_iris()
x=iris.data
y=iris.target
print(x.shape)
print(y.shape)
(150, 4)
(150,)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(x)






k_size = 0.25
r_seeds = 100
X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = k_size, random_state=r_seeds)
print("Shape of X_train: ", X_train.shape)
print("Shape of X_test: ", X_test.shape)
print("Shape of y_train: ", y_train.shape)
print("Shape of y_test: ", y_test.shape)
Shape of X_train: (112, 4)
Shape of X_test: (38, 4)
Shape of y_train: (112,)
Shape of y_test: (38,)




deci_tree = DecisionTreeClassifier(criterion='entropy')deci_tree.fit(X_train, y_train)
prediction = deci_tree.predict(X_test)
cm = confusion_matrix(y_test, prediction)
plt.figure(figsize=(3, 3))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()
# Plot the decision tree
plt.figure(figsize=(8, 8))
plot_tree(deci_tree, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)
plt.show()
accuracy_dt = accuracy_score(y_test, prediction)
print("Accuracy on Hold Out method using classification:", accuracy_dt*100,"%")
report = classification_report(y_test, prediction)
print("Classification Report:\n", report)





knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
prediction2 = knn.predict(X_test)
# Ignore FutureWarning from scikit-learn
warnings.filterwarnings("ignore", category=FutureWarning)accuracy_knn = accuracy_score(y_test, prediction2)
print("Accuracy on Hold Out method using classification:", accuracy_knn*100,"%")
report = classification_report(y_test, prediction2)
print("Classification Report:\n", report)



nb = GaussianNB()
nb.fit(X_train, y_train)
GaussianNB()
prediction3 = nb.predict(X_test)
accuracy_nb = accuracy_score(y_test, prediction3)
print("Accuracy on Hold Out method using classification:", accuracy_nb*100,"%")
report = classification_report(y_test, prediction3)
print("Classification Report:\n", report)




iris = load_iris()
x = iris.data
y = iris.target
subsample_size = 25
test_size = 0.25 # 25% of the data will be used for testingindices = np.random.choice(len(x), size=subsample_size, replace=True)x_subsample = x[indices]
y_subsample = y[indices]
# Split the subsampled data into training and testing setsX_train, X_test, y_train, y_test = train_test_split(x_subsample, y_subsample, test_size=test_size, random_state=42)
# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
# Train Decision Tree Classifier on the scaled training datadeci_tree = DecisionTreeClassifier(criterion="entropy")deci_tree.fit(X_train_scaled, y_train)
# Predict on the scaled test data
y_pred = deci_tree.predict(X_test_scaled)
# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)



# Generate classification report
report = classification_report(y_test, y_pred,
target_names=iris.target_names)
print("Classification Report:")
print(report)


